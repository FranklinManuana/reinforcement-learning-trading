{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff7ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf \n",
    "\n",
    "\n",
    "import torch\n",
    "import sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import datetime\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd93deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# company ticker symbol\n",
    "ticker = 'NVDA'\n",
    "df = yf.download(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show stock plot over the years\n",
    "df.Close.plot(figure=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df['Close'] = scalar.fit_transform(df['Close'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347dc96d",
   "metadata": {},
   "source": [
    "### Trading Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv:\n",
    "    def __init__(self, data, window_size = 30, initial_balance = 10000):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.initial_balance = initial_balance\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = self.window_size\n",
    "        self.balance = self.initial_balance\n",
    "        self.shares_held = 0\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.done = False\n",
    "        return self.getStates()\n",
    "    \n",
    "    def getStates(self):\n",
    "        state = self.data[self.current_step - self.window_size:self.current_step].values\n",
    "        return np.concatenate([state.flatten(), [self.balance, self.shares_held]])\n",
    "    \n",
    "    def step(self, action):\n",
    "        price = self.data.iloc[self.current_step]['close']\n",
    "        prev_net = self.net_worth\n",
    "        reward = 0\n",
    "\n",
    "        if action == 1: # Buy\n",
    "            if self.balance >= price:\n",
    "                self.balance -= price\n",
    "                self.shares_held += 1 \n",
    "        elif action == 2: # sell\n",
    "            if self.shares_held > 0:\n",
    "                self.balance += price \n",
    "                self.shares_held -= 1\n",
    "                reward = 1\n",
    "    \n",
    "    self.current_step += 1\n",
    "    self.done = self.current_step >= len(self.df)\n",
    "    self.net_worth = self.balance + self.shares_held * price\n",
    "    reward = self.net_worth - prev_net\n",
    "\n",
    "    return self.getStates(), reward, self.done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ecc8e4",
   "metadata": {},
   "source": [
    "Network architecture using leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d180fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_features = 5 # OHLCV\n",
    "window_size = 30 # 30-day trading window\n",
    "N_states = N_features * window_size \n",
    "\n",
    "class TradingNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TradingNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(N_states,8192)\n",
    "        self.fc2 = torch.nn.Linear(8192,1024)\n",
    "        self.fc3 = torch.nn.Linear(1024,3)\n",
    "        self.activ = torch.nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x =self.activ(self.fc1(x))\n",
    "        x = self.activ(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188b555",
   "metadata": {},
   "source": [
    "### Replay Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Replay class will be constructed here'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dde961",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Initial model settings will be here '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c33d94",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_data(ticker, start=\"2020-01-01\", end=\"2023-12-31\"):\n",
    "    #load stock data while also cleaning columns of interest\n",
    "    data = yf.download(ticker, start=start, end=end)[[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]].fillna(method='ffill')\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    data = stock_data()\n",
    "    env = TradingEnv(data,30)#30 is for days\n",
    "    action_size = 3 # buy,sell, hold\n",
    "    model = TradingNet() # neural network\n",
    "\n",
    "    #network setup\n",
    "    target_model = TradingNet()\n",
    "    target_model.load_state_dict(model.state_dict())\n",
    "\n",
    "    net = TradingNet().cuda()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Training Loop\n",
    "    for episode in range(EPISODES):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if np.random.rand() <= EPSILON:\n",
    "                action = random.randrange(action_size)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    action = torch.argmax(model(torch.FloatTensor(state))).item()\n",
    "            \n",
    "            next_state, reward, done = env.step(action)\n",
    "            replay_buff.push(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "            # Replay\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ad7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc4044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
